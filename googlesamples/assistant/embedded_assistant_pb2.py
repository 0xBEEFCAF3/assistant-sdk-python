# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/speech/v1/cloud_speech.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from google.rpc import status_pb2 as google_dot_rpc_dot_status__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='google/speech/v1/cloud_speech.proto',
  package='google.assistant.embedded.v1alpha1',
  syntax='proto3',
  serialized_pb=_b('\n#google/speech/v1/cloud_speech.proto\x12\"google.assistant.embedded.v1alpha1\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/rpc/status.proto\"\xaa\x01\n\x0e\x43onverseConfig\x12J\n\x0f\x61udio_in_config\x18\x01 \x01(\x0b\x32\x31.google.assistant.embedded.v1alpha1.AudioInConfig\x12L\n\x10\x61udio_out_config\x18\x02 \x01(\x0b\x32\x32.google.assistant.embedded.v1alpha1.AudioOutConfig\"\xe9\x02\n\rAudioInConfig\x12L\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32:.google.assistant.embedded.v1alpha1.AudioInConfig.Encoding\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x1b\n\x13\x61udio_channel_count\x18\x03 \x01(\x05\x12\x15\n\rlanguage_code\x18\x04 \x01(\t\x12I\n\x0espeech_context\x18\x05 \x01(\x0b\x32\x31.google.assistant.embedded.v1alpha1.SpeechContext\x12\x12\n\nauth_token\x18\x64 \x01(\t\"\\\n\x08\x45ncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x08\n\x04\x46LAC\x10\x02\x12\t\n\x05MULAW\x10\x03\x12\x07\n\x03\x41MR\x10\x04\x12\n\n\x06\x41MR_WB\x10\x05\" \n\rSpeechContext\x12\x0f\n\x07phrases\x18\x01 \x03(\t\"\xee\x01\n\x0e\x41udioOutConfig\x12M\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32;.google.assistant.embedded.v1alpha1.AudioOutConfig.Encoding\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x19\n\x11volume_percentage\x18\x03 \x01(\x05\"W\n\x08\x45ncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x07\n\x03MP3\x10\x02\x12\x0f\n\x0bOPUS_IN_OGG\x10\x03\x12\t\n\x05MULAW\x10\x04\"X\n\x08\x41udioOut\x12\x16\n\naudio_data\x18\x01 \x01(\x0c\x42\x02\x08\x01\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x19\n\x11volume_percentage\x18\x03 \x01(\x05\"\x83\x01\n\x0f\x43onverseRequest\x12\x44\n\x06\x63onfig\x18\x01 \x01(\x0b\x32\x32.google.assistant.embedded.v1alpha1.ConverseConfigH\x00\x12\x16\n\x08\x61udio_in\x18\x02 \x01(\x0c\x42\x02\x08\x01H\x00\x42\x12\n\x10\x63onverse_request\"\xbe\x02\n\x10\x43onverseResponse\x12#\n\x05\x65rror\x18\x01 \x01(\x0b\x32\x12.google.rpc.StatusH\x00\x12T\n\nevent_type\x18\x02 \x01(\x0e\x32>.google.assistant.embedded.v1alpha1.ConverseResponse.EventTypeH\x00\x12\x41\n\taudio_out\x18\x03 \x01(\x0b\x32,.google.assistant.embedded.v1alpha1.AudioOutH\x00\x12\x18\n\x0e\x61ssistant_text\x18\x04 \x01(\tH\x00\"=\n\tEventType\x12\x1a\n\x16\x45VENT_TYPE_UNSPECIFIED\x10\x00\x12\x14\n\x10\x45ND_OF_UTTERANCE\x10\x01\x42\x13\n\x11\x63onverse_response2\x8e\x01\n\x11\x45mbeddedAssistant\x12y\n\x08\x43onverse\x12\x33.google.assistant.embedded.v1alpha1.ConverseRequest\x1a\x34.google.assistant.embedded.v1alpha1.ConverseResponse(\x01\x30\x01\x42:\n&com.google.assistant.embedded.v1alpha1B\x0e\x41ssistantProtoP\x01\x62\x06proto3')
  ,
  dependencies=[google_dot_api_dot_annotations__pb2.DESCRIPTOR,google_dot_rpc_dot_status__pb2.DESCRIPTOR,])
_sym_db.RegisterFileDescriptor(DESCRIPTOR)



_AUDIOINCONFIG_ENCODING = _descriptor.EnumDescriptor(
  name='Encoding',
  full_name='google.assistant.embedded.v1alpha1.AudioInConfig.Encoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FLAC', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MULAW', index=3, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR', index=4, number=4,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR_WB', index=5, number=5,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=573,
  serialized_end=665,
)
_sym_db.RegisterEnumDescriptor(_AUDIOINCONFIG_ENCODING)

_AUDIOOUTCONFIG_ENCODING = _descriptor.EnumDescriptor(
  name='Encoding',
  full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.Encoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MP3', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='OPUS_IN_OGG', index=3, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MULAW', index=4, number=4,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=853,
  serialized_end=940,
)
_sym_db.RegisterEnumDescriptor(_AUDIOOUTCONFIG_ENCODING)

_CONVERSERESPONSE_EVENTTYPE = _descriptor.EnumDescriptor(
  name='EventType',
  full_name='google.assistant.embedded.v1alpha1.ConverseResponse.EventType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='EVENT_TYPE_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_UTTERANCE', index=1, number=1,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=1403,
  serialized_end=1464,
)
_sym_db.RegisterEnumDescriptor(_CONVERSERESPONSE_EVENTTYPE)


_CONVERSECONFIG = _descriptor.Descriptor(
  name='ConverseConfig',
  full_name='google.assistant.embedded.v1alpha1.ConverseConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='audio_in_config', full_name='google.assistant.embedded.v1alpha1.ConverseConfig.audio_in_config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_out_config', full_name='google.assistant.embedded.v1alpha1.ConverseConfig.audio_out_config', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=131,
  serialized_end=301,
)


_AUDIOINCONFIG = _descriptor.Descriptor(
  name='AudioInConfig',
  full_name='google.assistant.embedded.v1alpha1.AudioInConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_channel_count', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.audio_channel_count', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='language_code', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.language_code', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='speech_context', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.speech_context', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='auth_token', full_name='google.assistant.embedded.v1alpha1.AudioInConfig.auth_token', index=5,
      number=100, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _AUDIOINCONFIG_ENCODING,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=304,
  serialized_end=665,
)


_SPEECHCONTEXT = _descriptor.Descriptor(
  name='SpeechContext',
  full_name='google.assistant.embedded.v1alpha1.SpeechContext',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='phrases', full_name='google.assistant.embedded.v1alpha1.SpeechContext.phrases', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=667,
  serialized_end=699,
)


_AUDIOOUTCONFIG = _descriptor.Descriptor(
  name='AudioOutConfig',
  full_name='google.assistant.embedded.v1alpha1.AudioOutConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='volume_percentage', full_name='google.assistant.embedded.v1alpha1.AudioOutConfig.volume_percentage', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _AUDIOOUTCONFIG_ENCODING,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=702,
  serialized_end=940,
)


_AUDIOOUT = _descriptor.Descriptor(
  name='AudioOut',
  full_name='google.assistant.embedded.v1alpha1.AudioOut',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='audio_data', full_name='google.assistant.embedded.v1alpha1.AudioOut.audio_data', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='google.assistant.embedded.v1alpha1.AudioOut.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='volume_percentage', full_name='google.assistant.embedded.v1alpha1.AudioOut.volume_percentage', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=942,
  serialized_end=1030,
)


_CONVERSEREQUEST = _descriptor.Descriptor(
  name='ConverseRequest',
  full_name='google.assistant.embedded.v1alpha1.ConverseRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_in', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.audio_in', index=1,
      number=2, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='converse_request', full_name='google.assistant.embedded.v1alpha1.ConverseRequest.converse_request',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1033,
  serialized_end=1164,
)


_CONVERSERESPONSE = _descriptor.Descriptor(
  name='ConverseResponse',
  full_name='google.assistant.embedded.v1alpha1.ConverseResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='error', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.error', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='event_type', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.event_type', index=1,
      number=2, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_out', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.audio_out', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='assistant_text', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.assistant_text', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _CONVERSERESPONSE_EVENTTYPE,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='converse_response', full_name='google.assistant.embedded.v1alpha1.ConverseResponse.converse_response',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1167,
  serialized_end=1485,
)

_CONVERSECONFIG.fields_by_name['audio_in_config'].message_type = _AUDIOINCONFIG
_CONVERSECONFIG.fields_by_name['audio_out_config'].message_type = _AUDIOOUTCONFIG
_AUDIOINCONFIG.fields_by_name['encoding'].enum_type = _AUDIOINCONFIG_ENCODING
_AUDIOINCONFIG.fields_by_name['speech_context'].message_type = _SPEECHCONTEXT
_AUDIOINCONFIG_ENCODING.containing_type = _AUDIOINCONFIG
_AUDIOOUTCONFIG.fields_by_name['encoding'].enum_type = _AUDIOOUTCONFIG_ENCODING
_AUDIOOUTCONFIG_ENCODING.containing_type = _AUDIOOUTCONFIG
_CONVERSEREQUEST.fields_by_name['config'].message_type = _CONVERSECONFIG
_CONVERSEREQUEST.oneofs_by_name['converse_request'].fields.append(
  _CONVERSEREQUEST.fields_by_name['config'])
_CONVERSEREQUEST.fields_by_name['config'].containing_oneof = _CONVERSEREQUEST.oneofs_by_name['converse_request']
_CONVERSEREQUEST.oneofs_by_name['converse_request'].fields.append(
  _CONVERSEREQUEST.fields_by_name['audio_in'])
_CONVERSEREQUEST.fields_by_name['audio_in'].containing_oneof = _CONVERSEREQUEST.oneofs_by_name['converse_request']
_CONVERSERESPONSE.fields_by_name['error'].message_type = google_dot_rpc_dot_status__pb2._STATUS
_CONVERSERESPONSE.fields_by_name['event_type'].enum_type = _CONVERSERESPONSE_EVENTTYPE
_CONVERSERESPONSE.fields_by_name['audio_out'].message_type = _AUDIOOUT
_CONVERSERESPONSE_EVENTTYPE.containing_type = _CONVERSERESPONSE
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['error'])
_CONVERSERESPONSE.fields_by_name['error'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['event_type'])
_CONVERSERESPONSE.fields_by_name['event_type'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['audio_out'])
_CONVERSERESPONSE.fields_by_name['audio_out'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
_CONVERSERESPONSE.oneofs_by_name['converse_response'].fields.append(
  _CONVERSERESPONSE.fields_by_name['assistant_text'])
_CONVERSERESPONSE.fields_by_name['assistant_text'].containing_oneof = _CONVERSERESPONSE.oneofs_by_name['converse_response']
DESCRIPTOR.message_types_by_name['ConverseConfig'] = _CONVERSECONFIG
DESCRIPTOR.message_types_by_name['AudioInConfig'] = _AUDIOINCONFIG
DESCRIPTOR.message_types_by_name['SpeechContext'] = _SPEECHCONTEXT
DESCRIPTOR.message_types_by_name['AudioOutConfig'] = _AUDIOOUTCONFIG
DESCRIPTOR.message_types_by_name['AudioOut'] = _AUDIOOUT
DESCRIPTOR.message_types_by_name['ConverseRequest'] = _CONVERSEREQUEST
DESCRIPTOR.message_types_by_name['ConverseResponse'] = _CONVERSERESPONSE

ConverseConfig = _reflection.GeneratedProtocolMessageType('ConverseConfig', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSECONFIG,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseConfig)
  ))
_sym_db.RegisterMessage(ConverseConfig)

AudioInConfig = _reflection.GeneratedProtocolMessageType('AudioInConfig', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOINCONFIG,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioInConfig)
  ))
_sym_db.RegisterMessage(AudioInConfig)

SpeechContext = _reflection.GeneratedProtocolMessageType('SpeechContext', (_message.Message,), dict(
  DESCRIPTOR = _SPEECHCONTEXT,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.SpeechContext)
  ))
_sym_db.RegisterMessage(SpeechContext)

AudioOutConfig = _reflection.GeneratedProtocolMessageType('AudioOutConfig', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOOUTCONFIG,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioOutConfig)
  ))
_sym_db.RegisterMessage(AudioOutConfig)

AudioOut = _reflection.GeneratedProtocolMessageType('AudioOut', (_message.Message,), dict(
  DESCRIPTOR = _AUDIOOUT,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.AudioOut)
  ))
_sym_db.RegisterMessage(AudioOut)

ConverseRequest = _reflection.GeneratedProtocolMessageType('ConverseRequest', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSEREQUEST,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseRequest)
  ))
_sym_db.RegisterMessage(ConverseRequest)

ConverseResponse = _reflection.GeneratedProtocolMessageType('ConverseResponse', (_message.Message,), dict(
  DESCRIPTOR = _CONVERSERESPONSE,
  __module__ = 'google.speech.v1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseResponse)
  ))
_sym_db.RegisterMessage(ConverseResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n&com.google.assistant.embedded.v1alpha1B\016AssistantProtoP\001'))
_AUDIOOUT.fields_by_name['audio_data'].has_options = True
_AUDIOOUT.fields_by_name['audio_data']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
_CONVERSEREQUEST.fields_by_name['audio_in'].has_options = True
_CONVERSEREQUEST.fields_by_name['audio_in']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\010\001'))
import grpc
from grpc.beta import implementations as beta_implementations
from grpc.beta import interfaces as beta_interfaces
from grpc.framework.common import cardinality
from grpc.framework.interfaces.face import utilities as face_utilities


class EmbeddedAssistantStub(object):
  """Service that implements Embedded Google Assistant API.
  """

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Converse = channel.stream_stream(
        '/google.assistant.embedded.v1alpha1.EmbeddedAssistant/Converse',
        request_serializer=ConverseRequest.SerializeToString,
        response_deserializer=ConverseResponse.FromString,
        )


class EmbeddedAssistantServicer(object):
  """Service that implements Embedded Google Assistant API.
  """

  def Converse(self, request_iterator, context):
    """Initiates or continues a conversation with the embedded assistant service.
    Each call performs one round-trip, sending an audio request to the service
    and receiving the audio response. Uses bidirectional streaming to receive
    results, such as the `END_OF_UTTERANCE` event, while sending audio.

    A conversation is one or more gRPC connections, each consisting of several
    streamed requests and responses. For example, if the user said "Set timer"
    and the assistant responds "For how long?", the sequence could be:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out

    Then the user says "Two minutes" and the assistant responds
    "Two minute timer, starting now". This is sent as another gRPC connection
    call to the `Converse` method, again with streamed requests and responses,
    such as:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_EmbeddedAssistantServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Converse': grpc.stream_stream_rpc_method_handler(
          servicer.Converse,
          request_deserializer=ConverseRequest.FromString,
          response_serializer=ConverseResponse.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'google.assistant.embedded.v1alpha1.EmbeddedAssistant', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))


class BetaEmbeddedAssistantServicer(object):
  """Service that implements Embedded Google Assistant API.
  """
  def Converse(self, request_iterator, context):
    """Initiates or continues a conversation with the embedded assistant service.
    Each call performs one round-trip, sending an audio request to the service
    and receiving the audio response. Uses bidirectional streaming to receive
    results, such as the `END_OF_UTTERANCE` event, while sending audio.

    A conversation is one or more gRPC connections, each consisting of several
    streamed requests and responses. For example, if the user said "Set timer"
    and the assistant responds "For how long?", the sequence could be:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out

    Then the user says "Two minutes" and the assistant responds
    "Two minute timer, starting now". This is sent as another gRPC connection
    call to the `Converse` method, again with streamed requests and responses,
    such as:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    """
    context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


class BetaEmbeddedAssistantStub(object):
  """Service that implements Embedded Google Assistant API.
  """
  def Converse(self, request_iterator, timeout, metadata=None, with_call=False, protocol_options=None):
    """Initiates or continues a conversation with the embedded assistant service.
    Each call performs one round-trip, sending an audio request to the service
    and receiving the audio response. Uses bidirectional streaming to receive
    results, such as the `END_OF_UTTERANCE` event, while sending audio.

    A conversation is one or more gRPC connections, each consisting of several
    streamed requests and responses. For example, if the user said "Set timer"
    and the assistant responds "For how long?", the sequence could be:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out

    Then the user says "Two minutes" and the assistant responds
    "Two minute timer, starting now". This is sent as another gRPC connection
    call to the `Converse` method, again with streamed requests and responses,
    such as:

    ConverseRequest.config
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseRequest.audio_in
    ConverseResponse.event_type.END_OF_UTTERANCE
    ConverseResponse.event_type.assistant_text
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    ConverseResponse.event_type.audio_out
    """
    raise NotImplementedError()


def beta_create_EmbeddedAssistant_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
  request_deserializers = {
    ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseRequest.FromString,
  }
  response_serializers = {
    ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseResponse.SerializeToString,
  }
  method_implementations = {
    ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): face_utilities.stream_stream_inline(servicer.Converse),
  }
  server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
  return beta_implementations.server(method_implementations, options=server_options)


def beta_create_EmbeddedAssistant_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
  request_serializers = {
    ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseRequest.SerializeToString,
  }
  response_deserializers = {
    ('google.assistant.embedded.v1alpha1.EmbeddedAssistant', 'Converse'): ConverseResponse.FromString,
  }
  cardinalities = {
    'Converse': cardinality.Cardinality.STREAM_STREAM,
  }
  stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
  return beta_implementations.dynamic_stub(channel, 'google.assistant.embedded.v1alpha1.EmbeddedAssistant', cardinalities, options=stub_options)
# @@protoc_insertion_point(module_scope)
